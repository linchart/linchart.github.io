<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>TF-IDF原理及应用 | linchart</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="你说广州塔，我知道是在广州，你说黄果树瀑布，我知道是在贵州，你说布达拉宫，我知道是在拉萨，你说公交车，我都不知道你在说哪个城市的公交车。这就是TF-IDF。
概念及原理TF-IDF全称Term Frequency and Inverse Document Frequency，直译过来就是’词频-逆向文件频率’，’TF’是指某一个给定的词语在该文件中出现的频率，’IDF’是指总文件数除以包含该词的文">
<meta property="og:type" content="article">
<meta property="og:title" content="TF-IDF原理及应用">
<meta property="og:url" content="http://yoursite.com/posts/2017/03/15/TF-IDF.html">
<meta property="og:site_name" content="linchart">
<meta property="og:description" content="你说广州塔，我知道是在广州，你说黄果树瀑布，我知道是在贵州，你说布达拉宫，我知道是在拉萨，你说公交车，我都不知道你在说哪个城市的公交车。这就是TF-IDF。
概念及原理TF-IDF全称Term Frequency and Inverse Document Frequency，直译过来就是’词频-逆向文件频率’，’TF’是指某一个给定的词语在该文件中出现的频率，’IDF’是指总文件数除以包含该词的文">
<meta property="og:image" content="http://i.imgur.com/B1xMUhQ.png">
<meta property="og:image" content="http://i.imgur.com/oTT2Zpz.png">
<meta property="og:image" content="http://i.imgur.com/4jhJzZI.png">
<meta property="og:updated_time" content="2017-08-14T07:10:46.416Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TF-IDF原理及应用">
<meta name="twitter:description" content="你说广州塔，我知道是在广州，你说黄果树瀑布，我知道是在贵州，你说布达拉宫，我知道是在拉萨，你说公交车，我都不知道你在说哪个城市的公交车。这就是TF-IDF。
概念及原理TF-IDF全称Term Frequency and Inverse Document Frequency，直译过来就是’词频-逆向文件频率’，’TF’是指某一个给定的词语在该文件中出现的频率，’IDF’是指总文件数除以包含该词的文">
<meta name="twitter:image" content="http://i.imgur.com/B1xMUhQ.png">
  
    <link rel="alternate" href="/atom.xml" title="linchart" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">linchart</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">I&#39;m on the way to the future, where you are there.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Zoeken"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-TF-IDF" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/posts/2017/03/15/TF-IDF.html" class="article-date">
  <time datetime="2017-03-15T09:36:24.153Z" itemprop="datePublished">2017-03-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      TF-IDF原理及应用
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>你说广州塔，我知道是在广州，你说黄果树瀑布，我知道是在贵州，你说布达拉宫，我知道是在拉萨，你说公交车，我都不知道你在说哪个城市的公交车。这就是<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>。</p>
<h1 id="概念及原理"><a href="#概念及原理" class="headerlink" title="概念及原理"></a>概念及原理</h1><p><a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>全称Term Frequency and Inverse Document Frequency，直译过来就是’词频-逆向文件频率’，’TF’是指某一个给定的词语在该文件中出现的频率，’IDF’是指总文件数除以包含该词的文件数，再取对数。<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>一般用来评估在一堆语料库或一堆文件集中，某个字词对于该语料库或该文件的重要程度。怎么理解呢，举个例子，假设现在手上有10篇文章，‘水果’这个词在某一篇文章出现的频率很高，但是在这10篇文章中的仅有2篇文章提到，那么‘水果’这个词的<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>会很高，如果10篇文章中有8篇提到‘水果’这个词，那么这个词的‘<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>’会相对偏低。主要思想就是，一个词越能将一篇文章与其他文章区分开来，那么这个词的权重越高。<br><a id="more"></a></p>
<h1 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h1><h2 id="TF计算："><a href="#TF计算：" class="headerlink" title="TF计算："></a>TF计算：</h2><p><img src="http://i.imgur.com/B1xMUhQ.png" alt=""> </p>
<p>（markdown编辑数学公式还不怎么熟，先用mathtype搞好再截图吧）比如上面的例子，’水果’，’硬盘’在文章1（共有10个词）中出现的次数分别为2次，4次，那么:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">TF(水果) = 2/10 = 0.2   </div><div class="line">TF(硬盘) = 4/10 = 0.4</div></pre></td></tr></table></figure></p>
<h2 id="IDF计算："><a href="#IDF计算：" class="headerlink" title="IDF计算："></a>IDF计算：</h2><p><img src="http://i.imgur.com/oTT2Zpz.png" alt=""></p>
<p>如果这10篇文章中，有2篇文章包含有’水果’这个词，有5篇包含’硬盘’这个词，那么：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">IDF(水果) = <span class="built_in">log</span>(10/2) = 1.6094   </div><div class="line">IDF(硬盘) = <span class="built_in">log</span>(10/5) = 0.6931</div></pre></td></tr></table></figure></p>
<h2 id="TF-IDF计算"><a href="#TF-IDF计算" class="headerlink" title="TF-IDF计算"></a>TF-IDF计算</h2><p>算好TF和IDF之后，就可以计算’水果’和’硬盘’的<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>了，只需要将TF和IDF相乘就ok。<br><img src="http://i.imgur.com/4jhJzZI.png" alt=""><br>所以’水果’的TF-IDF为：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">0.2*1.6094</div></pre></td></tr></table></figure></p>
<p>‘硬盘’的TF-IDF为：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">0.4*0.6931</div></pre></td></tr></table></figure></p>
<p>如果算’水果’和’硬盘’这两个词与文章1的相关性呢，很简单，只要将这两个词的<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>加起来。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">0.2*1.6094 + 0.4*0.6931</div></pre></td></tr></table></figure></p>
<h1 id="python中计算TF-IDF"><a href="#python中计算TF-IDF" class="headerlink" title="python中计算TF-IDF"></a>python中计算TF-IDF</h1><h2 id="使用的工具"><a href="#使用的工具" class="headerlink" title="使用的工具"></a>使用的工具</h2><ul>
<li>jieba</li>
<li>scikit-learn</li>
</ul>
<h2 id="切词"><a href="#切词" class="headerlink" title="切词"></a>切词</h2><p>其实切词只是计算TF-IDF的前期准备工作，在对中文文本进行<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>计算的话，切词这一步应该是怎么也逃不过去了。平常工作中基本都是用jieba切词，这里也打算用jieba对文本进行处理。<br>例如我现在有5个文本：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">content = [[<span class="string">'萨德系统核心装备X波段雷达'</span>],[<span class="string">'美韩当局部署萨德的步伐也在加速进行'</span>],[<span class="string">'纵观如今的手机处理器市场已经不是高通一家独大的局面'</span>],[<span class="string">'三星的Exynos处理器以及华为的海思麒麟芯片这些年风头正盛'</span>],[<span class="string">'魅族每年数以千万计的销量对于芯片厂商的贡献也是不可小看的'</span>]]</div></pre></td></tr></table></figure></p>
<p>首先需要对文本进行切词，切词代码及结果如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_words</span><span class="params">(text)</span>:</span></div><div class="line">    results = []</div><div class="line">    <span class="keyword">for</span> content <span class="keyword">in</span> contents:</div><div class="line">        seg_list = jieba.cut(content[<span class="number">0</span>],cut_all=<span class="keyword">False</span>)</div><div class="line">        <span class="comment"># 实际应用过程中，这里需要去除停用词</span></div><div class="line">        seg = <span class="string">' '</span>.join(seg_list)</div><div class="line">        results.append(seg)</div><div class="line">    <span class="keyword">return</span> results</div><div class="line">result = cut_words(contents)</div><div class="line"></div><div class="line">result = [<span class="string">'萨德 系统核心 装备 X 波段 雷达'</span>, <span class="string">'美韩 当局 部署 萨德 的 步伐 也 在 加速 进行'</span>, <span class="string">'纵观 如今 的 手机 处理器 市场 已经 不是 高通 一家独大 的 局面'</span>, <span class="string">'三星 的 Exynos 处理器 以及 华为 的 海思 麒麟 芯片 这些 年 风头 正 盛'</span>, <span class="string">'魅族 每年 数以千万计 的 销量 对于 芯片 厂商 的 贡献 也 是 不可 小看 的'</span>]</div></pre></td></tr></table></figure></p>
<p>准备工作做好之后，我们就可以进行<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>计算了。</p>
<h2 id="词语转矩阵"><a href="#词语转矩阵" class="headerlink" title="词语转矩阵"></a>词语转矩阵</h2><p>词语转矩阵需要用到<a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank" rel="external">CountVectorizer</a>这个函数，其作用是统计词汇的数量，并转为矩阵。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</div><div class="line">vectorizer = CountVectorizer()</div><div class="line">vector_location = vectorizer.fit_transform(result)</div></pre></td></tr></table></figure></p>
<p>通过type(vector_location)可以看到，函数fit_transform把result二维数组表示成一个稀疏矩阵:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">print(type(vector_location))</div><div class="line"><span class="comment">#输出</span></div><div class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">scipy</span>.<span class="title">sparse</span>.<span class="title">csr</span>.<span class="title">csr_matrix</span>'&gt;</span></div></pre></td></tr></table></figure></p>
<p>同时可以看下，vercot_location的输出结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">print(vector_location)</div><div class="line"><span class="comment">#输出</span></div><div class="line"><span class="comment">#(0, 27)	1</span></div><div class="line"><span class="comment">#(0, 23)	1</span></div><div class="line"><span class="comment">#(0, 28)	1</span></div><div class="line"><span class="comment">#(0, 21)	1</span></div><div class="line"><span class="comment">#(0, 34)	1</span></div><div class="line"><span class="comment">#(1, 27)	1</span></div><div class="line"><span class="comment">#(1, 25)	1</span></div><div class="line"><span class="comment">#(1, 16)	1</span></div><div class="line"><span class="comment">#(1, 32)	1</span></div><div class="line"><span class="comment">#(1, 19)	1</span></div><div class="line"><span class="comment">#(1, 6)	    1</span></div><div class="line"><span class="comment">#(1, 31)	1</span></div><div class="line"><span class="comment">#(2, 24)	1</span></div><div class="line"><span class="comment">#(2, 10)	1</span></div><div class="line"><span class="comment">#(2, 17)	1</span></div><div class="line"><span class="comment">#(2, 9)	    1</span></div><div class="line"><span class="comment">#(2, 15)	1</span></div><div class="line"><span class="comment">#(2, 14)	1</span></div><div class="line"><span class="comment">#(2, 4)	    1</span></div><div class="line"><span class="comment">#(2, 36)	1</span></div><div class="line"><span class="comment">#(2, 1)	    1</span></div><div class="line"><span class="comment">#(2, 13)	1</span></div><div class="line"><span class="comment">#(3, 9)	    1</span></div><div class="line"><span class="comment">#(3, 2)	    1</span></div><div class="line"><span class="comment">#(3, 0)  	1</span></div><div class="line"><span class="comment">#(3, 5) 	1</span></div><div class="line"><span class="comment">#(3, 7) 	1</span></div><div class="line"><span class="comment">#(3, 22)	1</span></div><div class="line"><span class="comment">#(3, 38)	1</span></div><div class="line"><span class="comment">#(3, 26)	1</span></div><div class="line"><span class="comment">#(3, 30)	1</span></div><div class="line"><span class="comment">#(3, 35)	1</span></div><div class="line"><span class="comment">#(4, 26)	1</span></div><div class="line"><span class="comment">#(4, 37)	1</span></div><div class="line"><span class="comment">#(4, 20)	1</span></div><div class="line"><span class="comment">#(4, 18)	1</span></div><div class="line"><span class="comment">#(4, 33)	1</span></div><div class="line"><span class="comment">#(4, 11)	1</span></div><div class="line"><span class="comment">#(4, 8) 	1</span></div><div class="line"><span class="comment">#(4, 29)	1</span></div><div class="line"><span class="comment">#(4, 3)    	1</span></div><div class="line"><span class="comment">#(4, 12)	1</span></div></pre></td></tr></table></figure></p>
<p>输出结果表示的是这个稀疏矩阵的第几行第几列有值，比如(0, 27)    1表示矩阵的第0行第27列有值。<br>转成矩阵的形式之后，我们就可以很容易地算出每个词对应的<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">TF-IDF</a>了，这里使用<a href="http://lijiancheng0614.github.io/scikit-learn/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html" target="_blank" rel="external">TfidfTransformer</a>函数进行计算。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer</div><div class="line">transformer = TfidfTransformer()</div><div class="line">tf_idf = transformer.fit_transform(vector_location)</div><div class="line">print(type(tf_idf))</div><div class="line"><span class="comment">#输出，同样是稀疏矩阵的形式</span></div><div class="line"><span class="comment">#&lt;class 'scipy.sparse.csr.csr_matrix'&gt;</span></div><div class="line">print(tf_idf)</div><div class="line"><span class="comment">#输出</span></div><div class="line"><span class="comment">#(0, 34)	0.463693222732</span></div><div class="line"><span class="comment">#(0, 21)	0.463693222732</span></div><div class="line"><span class="comment">#(0, 28)	0.463693222732</span></div><div class="line"><span class="comment">#(0, 23)	0.463693222732</span></div><div class="line"><span class="comment">#(0, 27)	0.37410477245</span></div><div class="line"><span class="comment">#(1, 31)	0.387756660106</span></div><div class="line"><span class="comment">#(1, 6) 	0.387756660106</span></div><div class="line"><span class="comment">#(1, 19)	0.387756660106</span></div><div class="line"><span class="comment">#(1, 32)	0.387756660106</span></div><div class="line"><span class="comment">#(1, 16)	0.387756660106</span></div><div class="line"><span class="comment">#(1, 25)	0.387756660106</span></div><div class="line"><span class="comment">#(1, 27)	0.312839631859</span></div><div class="line"><span class="comment">#(2, 13)	0.321896111462</span></div><div class="line"><span class="comment">#(2, 1) 	0.321896111462</span></div><div class="line"><span class="comment">#(2, 36)	0.321896111462</span></div><div class="line"><span class="comment">#(2, 4) 	0.321896111462</span></div><div class="line"><span class="comment">#(2, 14)	0.321896111462</span></div><div class="line"><span class="comment">#(2, 15)	0.321896111462</span></div><div class="line"><span class="comment">#(2, 9) 	0.259703755905</span></div><div class="line"><span class="comment">#(2, 17)	0.321896111462</span></div><div class="line"><span class="comment">#(2, 10)	0.321896111462</span></div><div class="line"><span class="comment">#(2, 24)	0.321896111462</span></div><div class="line"><span class="comment">#(3, 35)	0.327880622184</span></div><div class="line"><span class="comment">#(3, 30)	0.327880622184</span></div><div class="line"><span class="comment">#(3, 26)	0.264532021474</span></div><div class="line"><span class="comment">#(3, 38)	0.327880622184</span></div><div class="line"><span class="comment">#(3, 22)	0.327880622184</span></div><div class="line"><span class="comment">#(3, 7) 	0.327880622184</span></div><div class="line"><span class="comment">#(3, 5) 	0.327880622184</span></div><div class="line"><span class="comment">#(3, 0) 	0.327880622184</span></div><div class="line"><span class="comment">#(3, 2) 	0.327880622184</span></div><div class="line"><span class="comment">#(3, 9) 	0.264532021474</span></div><div class="line"><span class="comment">#(4, 12)	0.321896111462</span></div><div class="line"><span class="comment">#(4, 3) 	0.321896111462</span></div><div class="line"><span class="comment">#(4, 29)	0.321896111462</span></div><div class="line"><span class="comment">#(4, 8) 	0.321896111462</span></div><div class="line"><span class="comment">#(4, 11)	0.321896111462</span></div><div class="line"><span class="comment">#(4, 33)	0.321896111462</span></div><div class="line"><span class="comment">#(4, 18)	0.321896111462</span></div><div class="line"><span class="comment">#(4, 20)	0.321896111462</span></div><div class="line"><span class="comment">#(4, 37)	0.321896111462</span></div><div class="line"><span class="comment">#(4, 26)	0.259703755905</span></div></pre></td></tr></table></figure></p>
<p>如果需要把稀疏矩阵转成平常用的行列形式的矩阵的话。这里可以使用todense()或者toarray()函数，前者是将稀疏矩阵转成matrix的形式，后者是将稀疏矩阵转成ndarray的形式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">weight = tf_idf.toarray()</div><div class="line"><span class="comment">#or</span></div><div class="line">weight1 = tf_idf.todense()</div><div class="line"></div><div class="line">print(weight)</div><div class="line"><span class="comment">#输出</span></div><div class="line"><span class="comment">#(5,39)</span></div></pre></td></tr></table></figure></p>
<p>这里还有一个问题，就是我怎么知道每个权重对应的是哪个词呢？这里可以将词作为列名，将数组转成Dataframe进行查看。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">word=vectorizer.get_feature_names()</div><div class="line">df = pd.DataFrame(weight)</div><div class="line">df.columns = word</div><div class="line">print(df)</div></pre></td></tr></table></figure></p>
<h1 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h1><p>最后照例附上本次分析的源代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding:utf-8</span></div><div class="line"><span class="comment">#author:linchart</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> jieba</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</div><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer</div><div class="line">contents = [[<span class="string">'萨德系统核心装备X波段雷达'</span>],\</div><div class="line">            [<span class="string">'美韩当局部署萨德的步伐也在加速进行'</span>],\</div><div class="line">            [<span class="string">'纵观如今的手机处理器市场已经不是高通一家独大的局面'</span>],\</div><div class="line">            [<span class="string">'三星的Exynos处理器以及华为的海思麒麟芯片这些年风头正盛'</span>],\</div><div class="line">            [<span class="string">'魅族每年数以千万计的销量对于芯片厂商的贡献也是不可小看的'</span>]]</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_words</span><span class="params">(text)</span>:</span></div><div class="line">    results = []</div><div class="line">    <span class="keyword">for</span> content <span class="keyword">in</span> contents:</div><div class="line">        seg_list = jieba.cut(content[<span class="number">0</span>],cut_all=<span class="keyword">False</span>)</div><div class="line">        <span class="comment"># 实际应用过程中，这里需要去除停用词</span></div><div class="line">        seg = <span class="string">' '</span>.join(seg_list)</div><div class="line">        results.append(seg)</div><div class="line">    <span class="keyword">return</span> results</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tf_idf</span><span class="params">(words)</span>:</span></div><div class="line">    vectorizer = CountVectorizer()</div><div class="line">    vector_location = vectorizer.fit_transform(result)</div><div class="line">    transformer = TfidfTransformer()</div><div class="line">    tf_idf = transformer.fit_transform(vector_location)</div><div class="line">    weight = tf_idf.toarray()</div><div class="line">    word = vectorizer.get_feature_names()</div><div class="line">    df = pd.DataFrame(weight)</div><div class="line">    df.columns = word</div><div class="line">    <span class="keyword">return</span> df</div><div class="line"></div><div class="line">result = cut_words(contents)</div><div class="line">df = tf_idf(result)</div><div class="line">print(df)</div></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/posts/2017/03/15/TF-IDF.html" data-id="cj7yomk090007os8su90hzs0w" class="article-share-link">Delen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/posts/2017/08/01/perceptron_model.html" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Nieuwer</strong>
      <div class="article-nav-title">
        
          感知机模型
        
      </div>
    </a>
  
  
    <a href="/posts/2017/03/13/WeChat_Article1.html" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ouder</strong>
      <div class="article-nav-title">爬取微信文章</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categorieën</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Labels</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分类模型/">分类模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/多分类模型/">多分类模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/对数线性模型/">对数线性模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/广义线性模型/">广义线性模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/最优化/">最优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/监督学习/">监督学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/python/" style="font-size: 12.5px;">python</a> <a href="/tags/分类模型/" style="font-size: 15px;">分类模型</a> <a href="/tags/多分类模型/" style="font-size: 10px;">多分类模型</a> <a href="/tags/对数线性模型/" style="font-size: 12.5px;">对数线性模型</a> <a href="/tags/广义线性模型/" style="font-size: 12.5px;">广义线性模型</a> <a href="/tags/最优化/" style="font-size: 10px;">最优化</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a> <a href="/tags/爬虫/" style="font-size: 10px;">爬虫</a> <a href="/tags/监督学习/" style="font-size: 17.5px;">监督学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archieven</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recente berichten</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/posts/2017/09/03/softmax.html">softmax</a>
          </li>
        
          <li>
            <a href="/posts/2017/09/02/logistic.html">逻辑回归</a>
          </li>
        
          <li>
            <a href="/posts/2017/09/02/SVM3.html">支持向量机（三）</a>
          </li>
        
          <li>
            <a href="/posts/2017/09/02/SVM2.html">支持向量机（二）</a>
          </li>
        
          <li>
            <a href="/posts/2017/08/10/SVM.html">支持向量机（一）</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 山久丰<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>